{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c41fd626",
   "metadata": {},
   "source": [
    "# ML Lab Sheet - 4 ðŸ“‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b1902",
   "metadata": {},
   "source": [
    "## Name: Anish Agarwal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285cc2b",
   "metadata": {},
   "source": [
    "## Question - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e377fd",
   "metadata": {},
   "source": [
    "### Importing Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa12146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134da2d8",
   "metadata": {},
   "source": [
    "### Importing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdd35e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\alofu\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.load_iris()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed6f6ec",
   "metadata": {},
   "source": [
    "### Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6232f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = data['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1716130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['data']\n",
    "X = np.array(X, dtype = int)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ab3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = pd.DataFrame(X)\n",
    "data_.columns = data['feature_names']\n",
    "data_['Output'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4adfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d16520",
   "metadata": {},
   "source": [
    "### Define Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b8df9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(col):\n",
    "    \n",
    "    counts = np.unique(col,return_counts=True)\n",
    "    N = float(col.shape[0])\n",
    "    \n",
    "    ent = 0.0\n",
    "    \n",
    "    for ix in counts[1]:\n",
    "        p  = ix/N\n",
    "        ent += (-1.0*p*np.log2(p))\n",
    "    \n",
    "    return ent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f73f3f",
   "metadata": {},
   "source": [
    "### Define Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c32d7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(x_data,key,val):\n",
    "    left,right = divide_data(x_data,key,val)\n",
    "    \n",
    "    #% of total samples are on left and right\n",
    "    l = float(left.shape[0])/x_data.shape[0]\n",
    "    r = float(right.shape[0])/x_data.shape[0]\n",
    "    \n",
    "    #All examples come to one side!\n",
    "    if left.shape[0] == 0 or right.shape[0] ==0:\n",
    "        return -1000000 #Min Information Gain\n",
    "    \n",
    "    i_gain = entropy(x_data.Output) - (l*entropy(left.Output)+r*entropy(right.Output))\n",
    "    return i_gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb150a1",
   "metadata": {},
   "source": [
    "### Dividing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c38fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_data(x_data,key,val):\n",
    "    x_right = pd.DataFrame([],columns=x_data.columns)\n",
    "    x_left = pd.DataFrame([],columns=x_data.columns)\n",
    "    \n",
    "    for ix in range(x_data.shape[0]):\n",
    "        val_ = x_data[key].loc[ix]\n",
    "        \n",
    "        if val_ > val:\n",
    "            x_right = x_right.append(x_data.loc[ix])\n",
    "        else:\n",
    "            x_left = x_left.append(x_data.loc[ix])\n",
    "            \n",
    "    return x_left,x_right\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8e8bd",
   "metadata": {},
   "source": [
    "### Finding Count Of 0, 1 And 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "371b2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_count(X_train):\n",
    "        count = []\n",
    "        count.append(X_train[X_train['Output'] == 0].shape[0])\n",
    "        count.append(X_train[X_train['Output'] == 1].shape[0])\n",
    "        count.append(X_train[X_train['Output'] == 2].shape[0])\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509817dd",
   "metadata": {},
   "source": [
    "### Decision Tree Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a363353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self,depth=0,max_depth=5):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.key = None\n",
    "        self.val = None\n",
    "        self.count = None\n",
    "        self.max_depth = max_depth\n",
    "        self.depth = depth\n",
    "        self.target = None\n",
    "    \n",
    "    def train(self,X_train,names):\n",
    "        \n",
    "        features = ['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)']\n",
    "        info_gains = []\n",
    "        \n",
    "        for ix in features:\n",
    "            i_gain = information_gain(X_train,ix,X_train[ix].mean())\n",
    "            info_gains.append(i_gain)\n",
    "            \n",
    "        self.key = features[np.argmax(info_gains)]\n",
    "        self.val = X_train[self.key].mean()\n",
    "        print(\"Level \" , self.depth)\n",
    "        self.count = find_count(X_train)\n",
    "        cnt = 0                            ##maintain to get if we have only 1 flower in this node\n",
    "        for i in range(len(self.count)):\n",
    "            if(self.count[i]):\n",
    "                print(\"Count of \" , names[i] , \" = \" , self.count[i])\n",
    "                cnt += 1\n",
    "        print(\"Current entropy = \" , entropy(X_train.Output))\n",
    "        if cnt != 1:\n",
    "            print(\"Splitting on Tree Features \",self.key,\"with information gain\",np.argmax(info_gains))\n",
    "        \n",
    "        data_left,data_right = divide_data(X_train,self.key,self.val)\n",
    "        data_left = data_left.reset_index(drop=True)\n",
    "        data_right = data_right.reset_index(drop=True)\n",
    "\n",
    "        if cnt == 1:\n",
    "            if X_train.Output.mean() >= 1.5:\n",
    "                self.target = names[2]\n",
    "            elif X_train.Output.mean() <= 0.5:\n",
    "                self.target = names[0]\n",
    "            else:\n",
    "                self.target = names[1]\n",
    "            print(\"Reached leaf Node\")\n",
    "            print()\n",
    "            print()\n",
    "            return\n",
    "        \n",
    "        #Stop earyly when depth >=max depth\n",
    "        if(self.depth>=self.max_depth):\n",
    "            if X_train.Output.mean() >= 1.5:\n",
    "                self.target = names[2]\n",
    "            elif X_train.Output.mean() <= 0.5:\n",
    "                self.target = names[0]\n",
    "            else:\n",
    "                self.target = names[1]\n",
    "            print(\"Max depth Reached\")\n",
    "            print()\n",
    "            print()\n",
    "            return\n",
    "        \n",
    "        print()\n",
    "        print()\n",
    "        \n",
    "        self.left = DecisionTree(depth=self.depth+1,max_depth=self.max_depth)\n",
    "        self.left.train(data_left, names)\n",
    "        \n",
    "        self.right = DecisionTree(depth=self.depth+1,max_depth=self.max_depth)\n",
    "        self.right.train(data_right, names)\n",
    "\n",
    "        if X_train.Output.mean() >= 1.5:\n",
    "            self.target = names[2]\n",
    "        elif X_train.Output.mean() <= 0.5:\n",
    "            self.target = names[0]\n",
    "        else:\n",
    "            self.target = names[1]\n",
    "        return    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f657e184",
   "metadata": {},
   "source": [
    "### Making Object Of The Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a3cf633",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737aa7b",
   "metadata": {},
   "source": [
    "### Training Model On The DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d32464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level  0\n",
      "Count of  setosa  =  50\n",
      "Count of  versicolor  =  50\n",
      "Count of  virginica  =  50\n",
      "Current entropy =  1.584962500721156\n",
      "Splitting on Tree Features  petal width (cm) with information gain 3\n",
      "\n",
      "\n",
      "Level  1\n",
      "Count of  setosa  =  50\n",
      "Current entropy =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "\n",
      "Level  1\n",
      "Count of  versicolor  =  50\n",
      "Count of  virginica  =  50\n",
      "Current entropy =  1.0\n",
      "Splitting on Tree Features  petal length (cm) with information gain 2\n",
      "\n",
      "\n",
      "Level  2\n",
      "Count of  versicolor  =  48\n",
      "Count of  virginica  =  6\n",
      "Current entropy =  0.5032583347756457\n",
      "Splitting on Tree Features  petal width (cm) with information gain 3\n",
      "\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  48\n",
      "Count of  virginica  =  5\n",
      "Current entropy =  0.45079138835466503\n",
      "Splitting on Tree Features  petal length (cm) with information gain 2\n",
      "\n",
      "\n",
      "Level  4\n",
      "Count of  versicolor  =  11\n",
      "Current entropy =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "\n",
      "Level  4\n",
      "Count of  versicolor  =  37\n",
      "Count of  virginica  =  5\n",
      "Current entropy =  0.5266170655714281\n",
      "Splitting on Tree Features  sepal length (cm) with information gain 0\n",
      "\n",
      "\n",
      "Level  5\n",
      "Count of  versicolor  =  15\n",
      "Count of  virginica  =  1\n",
      "Current entropy =  0.3372900666170139\n",
      "Splitting on Tree Features  sepal length (cm) with information gain 0\n",
      "Max depth Reached\n",
      "\n",
      "\n",
      "Level  5\n",
      "Count of  versicolor  =  22\n",
      "Count of  virginica  =  4\n",
      "Current entropy =  0.6193821946787638\n",
      "Splitting on Tree Features  sepal length (cm) with information gain 0\n",
      "Max depth Reached\n",
      "\n",
      "\n",
      "Level  3\n",
      "Count of  virginica  =  1\n",
      "Current entropy =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "\n",
      "Level  2\n",
      "Count of  versicolor  =  2\n",
      "Count of  virginica  =  44\n",
      "Current entropy =  0.2580186686648155\n",
      "Splitting on Tree Features  petal width (cm) with information gain 3\n",
      "\n",
      "\n",
      "Level  3\n",
      "Count of  versicolor  =  2\n",
      "Count of  virginica  =  16\n",
      "Current entropy =  0.5032583347756457\n",
      "Splitting on Tree Features  sepal length (cm) with information gain 0\n",
      "\n",
      "\n",
      "Level  4\n",
      "Count of  versicolor  =  2\n",
      "Count of  virginica  =  12\n",
      "Current entropy =  0.5916727785823275\n",
      "Splitting on Tree Features  sepal length (cm) with information gain 0\n",
      "\n",
      "\n",
      "Level  5\n",
      "Count of  virginica  =  3\n",
      "Current entropy =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "\n",
      "Level  5\n",
      "Count of  versicolor  =  2\n",
      "Count of  virginica  =  9\n",
      "Current entropy =  0.6840384356390417\n",
      "Splitting on Tree Features  sepal width (cm) with information gain 1\n",
      "Max depth Reached\n",
      "\n",
      "\n",
      "Level  4\n",
      "Count of  virginica  =  4\n",
      "Current entropy =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "\n",
      "Level  3\n",
      "Count of  virginica  =  28\n",
      "Current entropy =  0.0\n",
      "Reached leaf Node\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt.train(data_, names)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb42a795",
   "metadata": {},
   "source": [
    "## Question- 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e69838",
   "metadata": {},
   "source": [
    "### Importing Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fbd05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69203c5d",
   "metadata": {},
   "source": [
    "### Importing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f755cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0               1000025                5                        1   \n",
       "1               1002945                5                        4   \n",
       "2               1015425                3                        1   \n",
       "3               1016277                6                        8   \n",
       "4               1017023                4                        1   \n",
       "..                  ...              ...                      ...   \n",
       "678              776715                3                        1   \n",
       "679              841769                2                        1   \n",
       "680              888820                5                       10   \n",
       "681              897471                4                        8   \n",
       "682              897471                4                        8   \n",
       "\n",
       "     Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                           1                  1                            2   \n",
       "1                           4                  5                            7   \n",
       "2                           1                  1                            2   \n",
       "3                           8                  1                            3   \n",
       "4                           1                  3                            2   \n",
       "..                        ...                ...                          ...   \n",
       "678                         1                  1                            3   \n",
       "679                         1                  1                            2   \n",
       "680                        10                  3                            7   \n",
       "681                         6                  4                            3   \n",
       "682                         8                  5                            4   \n",
       "\n",
       "     Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0              1                3                1        1      2  \n",
       "1             10                3                2        1      2  \n",
       "2              2                3                1        1      2  \n",
       "3              4                3                7        1      2  \n",
       "4              1                3                1        1      2  \n",
       "..           ...              ...              ...      ...    ...  \n",
       "678            2                1                1        1      2  \n",
       "679            1                1                1        1      2  \n",
       "680            3                8               10        2      4  \n",
       "681            4               10                6        1      4  \n",
       "682            5               10                4        1      4  \n",
       "\n",
       "[683 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('https://raw.githubusercontent.com/anishaga/Machine-Learning/main/Lab%20Sheet%204/cancer.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ae0a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850f8123",
   "metadata": {},
   "source": [
    "### Splitting The DataSet Into Training And Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f77938a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e98c57",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "147011ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad442d",
   "metadata": {},
   "source": [
    "### Training Model On Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccdb5389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4f13d",
   "metadata": {},
   "source": [
    "### Predicting Test Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4c0f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0629f20e",
   "metadata": {},
   "source": [
    "### Making Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70409e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   5]\n",
      " [  6  58]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4b164",
   "metadata": {},
   "source": [
    "### Finding Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb53b835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935672514619883"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114fd21",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db47b48",
   "metadata": {},
   "source": [
    "### Importing Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6eac786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9a3faf",
   "metadata": {},
   "source": [
    "### Importing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39ce57ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0               1000025                5                        1   \n",
       "1               1002945                5                        4   \n",
       "2               1015425                3                        1   \n",
       "3               1016277                6                        8   \n",
       "4               1017023                4                        1   \n",
       "..                  ...              ...                      ...   \n",
       "678              776715                3                        1   \n",
       "679              841769                2                        1   \n",
       "680              888820                5                       10   \n",
       "681              897471                4                        8   \n",
       "682              897471                4                        8   \n",
       "\n",
       "     Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                           1                  1                            2   \n",
       "1                           4                  5                            7   \n",
       "2                           1                  1                            2   \n",
       "3                           8                  1                            3   \n",
       "4                           1                  3                            2   \n",
       "..                        ...                ...                          ...   \n",
       "678                         1                  1                            3   \n",
       "679                         1                  1                            2   \n",
       "680                        10                  3                            7   \n",
       "681                         6                  4                            3   \n",
       "682                         8                  5                            4   \n",
       "\n",
       "     Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0              1                3                1        1      2  \n",
       "1             10                3                2        1      2  \n",
       "2              2                3                1        1      2  \n",
       "3              4                3                7        1      2  \n",
       "4              1                3                1        1      2  \n",
       "..           ...              ...              ...      ...    ...  \n",
       "678            2                1                1        1      2  \n",
       "679            1                1                1        1      2  \n",
       "680            3                8               10        2      4  \n",
       "681            4               10                6        1      4  \n",
       "682            5               10                4        1      4  \n",
       "\n",
       "[683 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('https://raw.githubusercontent.com/anishaga/Machine-Learning/main/Lab%20Sheet%204/cancer.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26f8d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ab7bf",
   "metadata": {},
   "source": [
    "### Splitting The DataSet Into Training And Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0350f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e34de94",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66b9d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c4943",
   "metadata": {},
   "source": [
    "### Training Model On Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13af07e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69301c1",
   "metadata": {},
   "source": [
    "### Predicting Test Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fbdf194",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722bc108",
   "metadata": {},
   "source": [
    "### Making Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4f9bf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   4]\n",
      " [  5  59]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a941119",
   "metadata": {},
   "source": [
    "### Finding Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38936814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5ff73d",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf43f57",
   "metadata": {},
   "source": [
    "### Importing Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d4a70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e37099",
   "metadata": {},
   "source": [
    "### Importing DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83c4bc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample code number</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0               1000025                5                        1   \n",
       "1               1002945                5                        4   \n",
       "2               1015425                3                        1   \n",
       "3               1016277                6                        8   \n",
       "4               1017023                4                        1   \n",
       "..                  ...              ...                      ...   \n",
       "678              776715                3                        1   \n",
       "679              841769                2                        1   \n",
       "680              888820                5                       10   \n",
       "681              897471                4                        8   \n",
       "682              897471                4                        8   \n",
       "\n",
       "     Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                           1                  1                            2   \n",
       "1                           4                  5                            7   \n",
       "2                           1                  1                            2   \n",
       "3                           8                  1                            3   \n",
       "4                           1                  3                            2   \n",
       "..                        ...                ...                          ...   \n",
       "678                         1                  1                            3   \n",
       "679                         1                  1                            2   \n",
       "680                        10                  3                            7   \n",
       "681                         6                  4                            3   \n",
       "682                         8                  5                            4   \n",
       "\n",
       "     Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0              1                3                1        1      2  \n",
       "1             10                3                2        1      2  \n",
       "2              2                3                1        1      2  \n",
       "3              4                3                7        1      2  \n",
       "4              1                3                1        1      2  \n",
       "..           ...              ...              ...      ...    ...  \n",
       "678            2                1                1        1      2  \n",
       "679            1                1                1        1      2  \n",
       "680            3                8               10        2      4  \n",
       "681            4               10                6        1      4  \n",
       "682            5               10                4        1      4  \n",
       "\n",
       "[683 rows x 11 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('https://raw.githubusercontent.com/anishaga/Machine-Learning/main/Lab%20Sheet%204/cancer.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "977ff93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5947ed",
   "metadata": {},
   "source": [
    "### Splitting The DataSet Into Training And Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1055c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0c529",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4027ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ec318",
   "metadata": {},
   "source": [
    "### Training Model On Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46bd5160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db09537",
   "metadata": {},
   "source": [
    "### Predicting Test Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b7dcb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615fdf9",
   "metadata": {},
   "source": [
    "### Making Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7b31d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99  8]\n",
      " [ 2 62]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b898db8",
   "metadata": {},
   "source": [
    "### Finding Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5414101f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415204678362573"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
