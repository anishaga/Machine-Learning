{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "65ecb259",
      "metadata": {
        "id": "65ecb259"
      },
      "source": [
        "## Importing Relevant Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "330a6fd0",
      "metadata": {
        "id": "330a6fd0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83542386",
      "metadata": {
        "id": "83542386"
      },
      "source": [
        "# Data PreProcessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading The DataSet Into Colab From GitHub"
      ],
      "metadata": {
        "id": "41TmlV7BbZ1d"
      },
      "id": "41TmlV7BbZ1d"
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "M8bq5e8ibWEu"
      },
      "id": "M8bq5e8ibWEu",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/anishaga/Machine-Learning/archive/refs/heads/main.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/tmp/cats-and-dogs.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LShDqCYbb9W",
        "outputId": "590634b1-f2b9-4c44-b35a-98b80d3589cb"
      },
      "id": "5LShDqCYbb9W",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-16 01:14:06--  https://github.com/anishaga/Machine-Learning/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/anishaga/Machine-Learning/zip/refs/heads/main [following]\n",
            "--2022-05-16 01:14:06--  https://codeload.github.com/anishaga/Machine-Learning/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 192.30.255.121\n",
            "Connecting to codeload.github.com (codeload.github.com)|192.30.255.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
            "\n",
            "/tmp/cats-and-dogs.     [ <=>                ] 226.72M  27.7MB/s    in 7.5s    \n",
            "\n",
            "2022-05-16 01:14:14 (30.0 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [237728825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef0ce899",
      "metadata": {
        "id": "ef0ce899"
      },
      "source": [
        "## PreProcessing The Training DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "567bb165",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "567bb165",
        "outputId": "d73b722f-4617-4c8c-b10b-d3b291e1f2d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/tmp/Machine-Learning-main/CNN/training_set', target_size = (64, 64), batch_size = 32, class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32ee4147",
      "metadata": {
        "id": "32ee4147"
      },
      "source": [
        "## PreProcessing The Testing DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e862074b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e862074b",
        "outputId": "96e6db15-f005-400f-919f-23d5572e9e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/tmp/Machine-Learning-main/CNN/test_set', target_size = (64,64), batch_size = 32, class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72f7bbcb",
      "metadata": {
        "id": "72f7bbcb"
      },
      "source": [
        "# Building The CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ea91b35",
      "metadata": {
        "id": "2ea91b35"
      },
      "source": [
        "## Initialising The CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cec57374",
      "metadata": {
        "id": "cec57374"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76101daa",
      "metadata": {
        "id": "76101daa"
      },
      "source": [
        "## Step - 1 : Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f8d8174d",
      "metadata": {
        "id": "f8d8174d"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', input_shape =[64,64,3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5534874",
      "metadata": {
        "id": "e5534874"
      },
      "source": [
        "## Step - 2: Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0b117640",
      "metadata": {
        "id": "0b117640"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fde7a68",
      "metadata": {
        "id": "1fde7a68"
      },
      "source": [
        "## Adding A Second Convolution Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a670d5bb",
      "metadata": {
        "id": "a670d5bb"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "389a1cd8",
      "metadata": {
        "id": "389a1cd8"
      },
      "source": [
        "## Step - 3: Flattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9ba7ea45",
      "metadata": {
        "id": "9ba7ea45"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad55950b",
      "metadata": {
        "id": "ad55950b"
      },
      "source": [
        "## Step-4: Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2723a751",
      "metadata": {
        "id": "2723a751"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2468202",
      "metadata": {
        "id": "b2468202"
      },
      "source": [
        "## Step- 5: Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "18e01f03",
      "metadata": {
        "id": "18e01f03"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7269a3ad",
      "metadata": {
        "id": "7269a3ad"
      },
      "source": [
        "# Training The CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05d5669e",
      "metadata": {
        "id": "05d5669e"
      },
      "source": [
        "## Compiling The CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ece322a4",
      "metadata": {
        "id": "ece322a4"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23d95f83",
      "metadata": {
        "id": "23d95f83"
      },
      "source": [
        "## Training The CNN On The Training Set And Evaluating It On The Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ca0f17f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca0f17f6",
        "outputId": "99c4cbea-dddd-4e5c-e9f3-68c8d503b0ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "250/250 [==============================] - 65s 257ms/step - loss: 0.6573 - accuracy: 0.6054 - val_loss: 0.5958 - val_accuracy: 0.6850\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 0.5879 - accuracy: 0.6869 - val_loss: 0.5884 - val_accuracy: 0.6875\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 61s 246ms/step - loss: 0.5530 - accuracy: 0.7185 - val_loss: 0.5927 - val_accuracy: 0.7100\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.5261 - accuracy: 0.7333 - val_loss: 0.5202 - val_accuracy: 0.7465\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.5064 - accuracy: 0.7523 - val_loss: 0.5096 - val_accuracy: 0.7490\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 0.4787 - accuracy: 0.7699 - val_loss: 0.5356 - val_accuracy: 0.7440\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 62s 248ms/step - loss: 0.4716 - accuracy: 0.7684 - val_loss: 0.4896 - val_accuracy: 0.7715\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 0.4581 - accuracy: 0.7807 - val_loss: 0.4820 - val_accuracy: 0.7805\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 61s 246ms/step - loss: 0.4506 - accuracy: 0.7880 - val_loss: 0.4617 - val_accuracy: 0.7825\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 61s 246ms/step - loss: 0.4283 - accuracy: 0.8005 - val_loss: 0.4850 - val_accuracy: 0.7865\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.4158 - accuracy: 0.8092 - val_loss: 0.4523 - val_accuracy: 0.7960\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 0.3986 - accuracy: 0.8200 - val_loss: 0.4852 - val_accuracy: 0.7910\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 0.3950 - accuracy: 0.8180 - val_loss: 0.4977 - val_accuracy: 0.7870\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 62s 248ms/step - loss: 0.3820 - accuracy: 0.8240 - val_loss: 0.5297 - val_accuracy: 0.7610\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 62s 248ms/step - loss: 0.3724 - accuracy: 0.8286 - val_loss: 0.4462 - val_accuracy: 0.8020\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 0.3676 - accuracy: 0.8338 - val_loss: 0.4479 - val_accuracy: 0.8090\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 62s 247ms/step - loss: 0.3479 - accuracy: 0.8444 - val_loss: 0.5026 - val_accuracy: 0.7885\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.3418 - accuracy: 0.8486 - val_loss: 0.4529 - val_accuracy: 0.7990\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.3270 - accuracy: 0.8547 - val_loss: 0.4418 - val_accuracy: 0.8090\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 62s 246ms/step - loss: 0.3172 - accuracy: 0.8620 - val_loss: 0.4716 - val_accuracy: 0.7910\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 61s 246ms/step - loss: 0.2915 - accuracy: 0.8755 - val_loss: 0.4853 - val_accuracy: 0.7925\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.2852 - accuracy: 0.8760 - val_loss: 0.4826 - val_accuracy: 0.8020\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 62s 246ms/step - loss: 0.2752 - accuracy: 0.8821 - val_loss: 0.5121 - val_accuracy: 0.7910\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 61s 245ms/step - loss: 0.2684 - accuracy: 0.8885 - val_loss: 0.5241 - val_accuracy: 0.7935\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 62s 246ms/step - loss: 0.2607 - accuracy: 0.8926 - val_loss: 0.5724 - val_accuracy: 0.7885\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdb563f3750>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebf8f840",
      "metadata": {
        "id": "ebf8f840"
      },
      "source": [
        "## Making A Single Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4ce08134",
      "metadata": {
        "id": "4ce08134"
      },
      "outputs": [],
      "source": [
        "test_image = image.load_img('/tmp/Machine-Learning-main/CNN/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6c261964",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c261964",
        "outputId": "51ee05bf-9469-40e0-9dcb-b08f7ab1482f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n"
          ]
        }
      ],
      "source": [
        "print(prediction)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "CNN1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}